{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277f2216",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1dbac-99d9-4751-b876-33b8edd72088",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03784e21-de5a-4fd7-997c-9d3547cacd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4790e61-d176-4da5-a9cb-9d5adf6fdc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba7450-7943-4972-a78a-53702a6decae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15cee81-0627-4849-bb1a-29437e324abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e7348-27be-4c4b-bc15-11a118986cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "from torch import nn, optim \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a82f356",
   "metadata": {},
   "source": [
    "![](Untitled-design.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e134b",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV=\"train.csv\"\n",
    "VALID_CSV=\"valid.csv\"\n",
    "\n",
    "BATCH_SIZE=128\n",
    "DEVICE=\"cpu\"\n",
    "\n",
    "MODEL_NAME=\"efficientnet_b0\"\n",
    "\n",
    "LR=0.001\n",
    "EPOCHS=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae556678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(TRAIN_CSV)\n",
    "df_valid=pd.read_csv(VALID_CSV)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"No. of examples present in df_train : {len(df_train)}\")\n",
    "print(f\"No. of examples present in df_valid : {len(df_valid)}\")\n",
    "print(f\"Labels are : {df_train['labels'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b822860",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=3100\n",
    "\n",
    "row=df_train.iloc[idx]\n",
    "image_pixels=np.array(row[:-1],dtype=np.float64)\n",
    "label=row.labels\n",
    "\n",
    "image=np.resize(image_pixels,(64,128))  #64*128=8192\n",
    "plt.imshow(image)\n",
    "plt.title(label);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fbae7",
   "metadata": {},
   "source": [
    "# Declare Spec Augmentations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e21ce4",
   "metadata": {},
   "source": [
    "![](image6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e831a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spec_augment import TimeMask, FreqMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26beff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return T.Compose([\n",
    "        TimeMask(T=15, num_masks=4),\n",
    "        FreqMask(F=15, num_masks=3)  #mask width and num\n",
    "    ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d063d20",
   "metadata": {},
   "source": [
    "# Create Custom Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give index and return image and label pair\n",
    "class SpecDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, augmentations=None):\n",
    "        self.df=df\n",
    "        self.augmentations=augmentations\n",
    "        \n",
    "        label_mapper={\n",
    "            \"Squiggle\":0,\n",
    "            \"Narrowband\":1,\n",
    "            \"Narrowbanddrd\":2,\n",
    "            \"Noises\":3\n",
    "        }\n",
    "        \n",
    "        self.df.loc[:,\"labels\"]=self.df.labels.map(label_mapper) #substitute text to num\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        row=self.df.iloc[idx]\n",
    "        image_pixels=np.array(row[:-1],dtype=np.float64)\n",
    "        \n",
    "        image=np.resize(image_pixels,(64,128,1))\n",
    "        label=np.array(row.labels,dtype=np.int64)\n",
    "        \n",
    "        image=torch.Tensor(image).permute(2,0,1)  #(c,h,w),pytorch image passing convention\n",
    "        \n",
    "        if self.augmentations!= None:\n",
    "            image=self.augmentations(image)\n",
    "            \n",
    "        return image.float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=SpecDataset(df_train,get_train_transform())\n",
    "validset=SpecDataset(df_valid)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e03ab580",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c164062",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = trainset[8]\n",
    "\n",
    "plt.imshow(image.permute(0, 1, 2).squeeze())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca164c71",
   "metadata": {},
   "source": [
    "# Load dataset into Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validloader=DataLoader(validset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb021438",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total no. of batches in trainloader : {len(trainloader)}\")\n",
    "print(f\"Total no. of batches in validloader : {len(validloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in trainloader:\n",
    "    break;\n",
    "\n",
    "print(f\"One image batch shape : {images.shape}\")\n",
    "print(f\"One label batch shape : {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a575fbe",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63618d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch image models\n",
    "class SpecModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SpecModel,self).__init__()\n",
    "        \n",
    "        self.net=timm.create_model(MODEL_NAME, num_classes=4, pretrained=True, in_chans=1) \n",
    "        \n",
    "    def forward(self, images, labels=None):\n",
    "        logits=self.net(images) #raw output without activation\n",
    "        \n",
    "        if labels != None:\n",
    "            loss=nn.CrossEntropyLoss()\n",
    "            return logits, loss(logits, labels)\n",
    "        \n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SpecModel()\n",
    "model;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374d1d7",
   "metadata": {},
   "source": [
    "# Create Train and Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878993e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm \n",
    "from utils import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, dataloader, optimizer, current_epoch):\n",
    "    model.train()\n",
    "    total_loss=0.0\n",
    "    total_acc=0.0\n",
    "    progress_bar=tqdm(dataloader, desc=\"EPOCH\"+\"[TRAIN]\"+str(current_epoch+1)+\"/\"+str(EPOCHS))\n",
    "    \n",
    "    for t, data in enumerate(progress_bar):\n",
    "        images, labels=data\n",
    "        images, labels=images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, loss=model(images, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss+= loss.item()\n",
    "        total_acc+= multiclass_accuracy(logits, labels)\n",
    "        \n",
    "        temp={'loss': '%6f' %float(total_loss/(t+1)), 'acc':'%6f' %float(total_acc/(t+1))}\n",
    "        \n",
    "        progress_bar.set_postfix(temp)\n",
    "    return total_loss/len(dataloader), total_acc/len(dataloader)\n",
    "                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da265107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, dataloader, current_epoch):\n",
    "    model.eval()\n",
    "    total_loss=0.0\n",
    "    total_acc=0.0\n",
    "    progress_bar=tqdm(dataloader, desc=\"EPOCH\"+\"[VALID]\"+str(current_epoch+1)+\"/\"+str(EPOCHS))\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for t, data in enumerate(progress_bar):\n",
    "            images, labels=data\n",
    "            images, labels=images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            logits, loss= model(images, labels)\n",
    "\n",
    "            total_loss+= loss.item()\n",
    "            total_acc+= multiclass_accuracy(logits, labels)\n",
    "\n",
    "            temp={'loss': '%6f' %float(total_loss/(t+1)), 'acc':'%6f' %float(total_acc/(t+1))}\n",
    "\n",
    "            progress_bar.set_postfix(temp)\n",
    "    return total_loss/len(dataloader), total_acc/len(dataloader)\n",
    "                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e2993",
   "metadata": {},
   "source": [
    "# Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ad498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model,trainloader, validloader, optimizer):\n",
    "    \n",
    "    best_valid_loss=np.Inf\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        train_loss, train_acc=train_fn(model, trainloader, optimizer, i)\n",
    "        valid_loss, valid_acc=eval_fn(model, validloader,i)\n",
    "        \n",
    "        if valid_loss< best_valid_loss:\n",
    "            torch.save(model.state_dict(), MODEL_NAME+\"-best-weights.pt\")\n",
    "            print(\"SAVED-BEST-WEIGHTS\")\n",
    "            \n",
    "            best_valid_loss=valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=LR)\n",
    "fit(model, trainloader, validloader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d568f60",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import view_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2706a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
